# ğŸ“¸ Photo Chat with Gemini - Next.js & Genkit Demo

A Next.js 15 application that demonstrates the power of **Genkit** with **Gemini AI** for multimodal conversations. Take photos and have voice/text conversations about them with AI!

## âœ¨ Features

- ğŸ“· **Photo Capture**: Use your camera or upload images
- ğŸ—£ï¸ **Voice Input**: Speak your questions using Web Speech API
- ğŸ¯ **Text Input**: Type your messages with auto-resize textarea
- ğŸ”Š **Voice Output**: Listen to AI responses with text-to-speech
- ğŸ’¬ **Conversation History**: Context-aware chat sessions
- ğŸ¤– **Gemini AI Integration**: Powered by Google's latest AI models
- ğŸ“± **Responsive Design**: Works on mobile and desktop

## ğŸ› ï¸ Tech Stack

- **Next.js 15** with App Router
- **Genkit** for AI integration
- **Gemini AI** (Vision + Text models)
- **TypeScript** for type safety
- **Tailwind CSS** for styling
- **Headless UI** for accessible components
- **Heroicons** for beautiful icons

## ğŸš€ Quick Start

### 1. Clone and Install

```bash
git clone <your-repo-url>
cd rendercon-ke-firebase-nextjs-demo
pnpm install
```

### 2. Environment Setup

Create a `.env.local` file:

```bash
cp .env.example .env.local
```

Add your Gemini API key:

```env
GEMINI_API_KEY=your_gemini_api_key_here
```

> Get your API key from [Google AI Studio](https://makersuite.google.com/app/apikey)

### 3. Run Development Server

```bash
pnpm dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

## ğŸ¯ Demo Flow

Perfect for presentations! Here's a suggested demo flow:

### 1. **Photo Capture Demo**
- Take a live photo of the audience
- Upload a code screenshot
- Capture a whiteboard diagram

### 2. **Voice Interaction Demo**
- Click the microphone button
- Ask "What do you see in this image?"
- Show real-time speech-to-text

### 3. **AI Response Demo**
- Watch the AI analyze the image
- Click "Play" to hear the response
- Continue the conversation with follow-up questions

### 4. **Technical Features**
- Show the session management
- Demonstrate context preservation
- Switch between voice and text modes

## ğŸ“± Usage Instructions

1. **Capture Photo**: Click "Take Photo" or "Upload Photo"
2. **Choose Input Mode**: Toggle between "Type" and "Voice"
3. **Ask Questions**: Speak or type questions about your image
4. **Listen to Responses**: Click the play button to hear AI responses
5. **Continue Conversation**: Ask follow-up questions with full context

## ğŸ—ï¸ Architecture

```
src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ actions/chat.ts      # Server actions for AI integration
â”‚   â””â”€â”€ page.tsx             # Main application page
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ PhotoCapture.tsx     # Camera/upload interface
â”‚   â”œâ”€â”€ VoiceInput.tsx       # Speech-to-text component
â”‚   â””â”€â”€ ChatInterface.tsx    # Chat UI with messages
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ genkit.ts           # Genkit configuration
â”‚   â”œâ”€â”€ session.ts          # Session management
â”‚   â””â”€â”€ utils.ts            # Utility functions
â””â”€â”€ types/
    â””â”€â”€ conversation.ts      # TypeScript interfaces
```

## ğŸ¨ Key Components

### PhotoCapture Component
- Camera access with fallback to file upload
- Real-time video preview
- Image capture and processing
- Clean, intuitive UI

### VoiceInput Component
- Web Speech API integration
- Real-time transcription display
- Visual feedback for recording state
- Browser compatibility checks

### ChatInterface Component
- Message history with timestamps
- Auto-scrolling to new messages
- Text-to-speech for AI responses
- Loading states and animations

## ğŸ”§ Server Actions

### `createChatSession()`
Creates a new conversation session for context management.

### `chatWithImage(sessionId, message, imageUrl?)`
Sends message to Gemini AI with optional image context.

### `getSessionHistory(sessionId)`
Retrieves conversation history for a session.

## ğŸŒ Deployment

### Vercel (Recommended)

```bash
pnpm build
vercel --prod
```

### Other Platforms

The app is a standard Next.js application and can be deployed to any platform that supports Node.js.

## ğŸ¯ Presentation Tips

1. **Test beforehand**: Ensure camera and microphone permissions work
2. **Have backup images**: Prepare interesting photos if live capture fails  
3. **Show different scenarios**: Code screenshots, diagrams, objects, people
4. **Demonstrate voice**: The voice interaction is the "wow factor"
5. **Highlight context**: Show how follow-up questions maintain context
6. **Show mobile**: Demonstrate responsive design on phone

## ğŸ” Troubleshooting

### Camera Not Working
- Check browser permissions
- Try different browsers (Chrome works best)
- Use the upload fallback option

### Voice Input Not Working  
- Enable microphone permissions
- Use HTTPS (required for speech recognition)
- Try Chrome or Safari

### AI Not Responding
- Check your API key in `.env.local`
- Verify internet connection
- Check browser console for errors

## ğŸ“š Learn More

- [Next.js Documentation](https://nextjs.org/docs)
- [Genkit Documentation](https://firebase.google.com/docs/genkit)
- [Gemini AI Documentation](https://ai.google.dev/)
- [Web Speech API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API)

## ğŸ¤ Contributing

This is a demo project for presentations, but feel free to fork and extend it for your own use cases!

## ğŸ“„ License

MIT License - feel free to use this for your presentations and demos.

---

**Built with â¤ï¸ for the Next.js & Genkit community**
